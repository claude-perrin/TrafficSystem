{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision import datapoints as dp\n",
    "    \n",
    "torch.manual_seed(17)\n",
    "\n",
    "\n",
    "\n",
    "# img = read_image('/Users/viktor/polsl/bachelor_project/DatasetTraffic/dataset/sec1/sec1_frame_004500.png')\n",
    "# bbox = [[372.94944000000004, 384.88014, 412.82976, 400.91058],[377.38944, 395.14985999999993, 415.40928, 411.62958], [123.80928, 554.7997799999999, 183.27936, 586.34982], [587.55072, 201.01014, 600.0, 208.75050000000002]]\n",
    "# bbox = torch.tensor(bbox, dtype=torch.int)\n",
    "# print(bbox)\n",
    "# print(bbox.size())\n",
    "\n",
    "# img=draw_bounding_boxes(img, bbox, width=3, colors=[(255,0,0),(0,255,0), (0,0,23), (25,25,25)])\n",
    "# img = torchvision.transforms.ToPILImage()(img)\n",
    "# img.show()\n",
    "def random_RGB_colors(num):\n",
    "    return [tuple(np.random.randint(1, 256, size=3)) for i in range(num)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1522.0695,  312.4100, 1544.4701,  338.6400],\n",
      "        [1594.5110,  287.3399, 1613.9203,  314.2697],\n",
      "        [1676.0900,  275.0495, 1696.4707,  298.8300],\n",
      "        [1730.0496,  248.5204, 1747.1587,  269.0501],\n",
      "        [1773.1210,  236.2797, 1787.9607,  258.0298],\n",
      "        [1841.9404,  194.3703, 1860.3110,  209.5303]]) [1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "class TrafficDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, transforms=None):\n",
    "        self.root_path = root_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.frames, self.labels = self.__get_frames_labels(self.root_path)\n",
    "    \n",
    "    \n",
    "    def __get_frames_labels(self, root_path):\n",
    "        frames = []\n",
    "        labels = []\n",
    "        for _, _, files in os.walk(self.root_path):\n",
    "            sorted_files = sorted(files)\n",
    "            for id, file in enumerate(sorted_files[1::2]):\n",
    "                labels.append(os.path.join(sec1, file))\n",
    "                frames.append(os.path.join(sec1, sorted_files[id*2]))\n",
    "        return tuple(frames), tuple(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame = dp.Image(read_image(self.frames[idx]))\n",
    "        label_txt = self.labels[idx]\n",
    "        \n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(label_txt) as f:\n",
    "            for vehicle in f.readlines():\n",
    "                vehicle_type, top_left_x, top_left_y, bottom_right_x, bottom_right_y = vehicle.split()\n",
    "                # xmin, ymin, xmax, ymax\n",
    "                boxes.append([float(top_left_x), float(top_left_y), float(bottom_right_x), float(bottom_right_y)])\n",
    "                labels.append(int(vehicle_type))\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        print(boxes, labels)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes  \n",
    "        target[\"label\"] = labels\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            frame, target = self.transforms(frame, target)\n",
    "        return frame, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "current_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "dataset_path = os.path.join(current_path, \"..\", \"DatasetTraffic\", \"dataset\", \"sec1\")\n",
    "\n",
    "obj = TrafficDataset(dataset_path)\n",
    "\n",
    "frame, target = obj[100]\n",
    "img = draw_bounding_boxes(frame, target[\"boxes\"], width=3, colors=random_RGB_colors(num=len(target[\"label\"])))\n",
    "img = torchvision.transforms.ToPILImage()(img)\n",
    "img.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
